#!/usr/bin/env python3
# -*- coding: utf-8 -*-
# Copyright (c) 2016 Mikkel Schubert <MikkelSch@gmail.com>
#
# Permission is hereby granted, free of charge, to any person obtaining a copy
# of this software and associated documentation files (the "Software"), to deal
# in the Software without restriction, including without limitation the rights
# to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
# copies of the Software, and to permit persons to whom the Software is
# furnished to do so, subject to the following conditions:
#
# The above copyright notice and this permission notice shall be included in
# all copies or substantial portions of the Software.
#
# THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
# IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
# FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
# AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
# LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
# OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
# SOFTWARE.
from __future__ import print_function

import argparse
import difflib
import errno
import gzip
import io
import itertools
import json
import multiprocessing
import os
import re
import shutil
import subprocess
import sys
import tempfile

from itertools import groupby
from shlex import quote


#############################################################################
_COLORS_ENABLED = True


def _do_print_color(*vargs, **kwargs):
    """Utility function: Prints using shell colors."""
    colorcode = kwargs.pop("colorcode")
    destination = kwargs.pop("file", sys.stdout)

    # No colors if output is redirected (e.g. less, file, etc.)
    if _COLORS_ENABLED and destination.isatty():
        vargs = list(vargs)
        for (index, varg) in enumerate(vargs):
            varg_lines = []
            # Newlines terminate the color-code for e.g. 'less', so ensure that
            # each line is color-coded, while preserving the list of arguments
            for line in str(varg).split("\n"):
                varg_lines.append("\033[00;%im%s\033[00m" % (colorcode, line))
            vargs[index] = "\n".join(varg_lines)

    print(*vargs, file=destination, **kwargs)

    if "\n" in kwargs.get("end", "\n"):
        destination.flush()


def print_ok(*vargs, **kwargs):
    """Equivalent to print, but prints using shell colorcodes (green)."""
    _do_print_color(*vargs, colorcode=32, **kwargs)


def print_warn(*vargs, **kwargs):
    """Equivalent to print, but prints using shell colorcodes (green)."""
    _do_print_color(*vargs, colorcode=33, **kwargs)


def print_err(*vargs, **kwargs):
    """Equivalent to print, but prints using shell colorcodes (red)."""
    _do_print_color(*vargs, colorcode=31, **kwargs)


#############################################################################
UNCOMPRESSED, GZIP = "raw", "gz"


def compress(value, compression):
    if compression == GZIP:
        return gzip.compress(value)
    else:
        assert False, compression


def decompress(filename):
    with open(filename, "rb") as handle:
        value = handle.read()

    header = value[:2]
    if filename.endswith(".gz"):
        if header != b"\x1f\x8b":
            raise TestError(
                "{} has .gz extension, but header is {!r}".format(filename, header)
            )

        value = gzip.decompress(value)

    value = value.decode("utf-8")
    return io.StringIO(value).readlines()


#############################################################################
_EXEC = "./build/AdapterRemoval"
_INFO_FILE = "info.json"
_INFO_FIELDS = {
    "arguments": list,
    "return_code": int,
    "stderr": list,
    "stdout": list,
    "exhaustive": bool,
    "skip": bool,
}


def pretty_output(s, padding=0, max_lines=float("inf")):
    padding = " " * padding
    lines = s.split("\n")
    if len(lines) > max_lines:
        lines = lines[:max_lines]
        lines.append("...")

    result = []
    for line in lines:
        result.append("%s>  %s" % (padding, line))

    return "\n".join(result)


def interleave(texts_1, texts_2):
    files = []

    for text_1, text_2 in zip(texts_1, texts_2):
        lines_1 = text_1.rstrip().split("\n")
        lines_2 = text_2.rstrip().split("\n")
        iters = (iter(lines_1).__next__, iter(lines_2).__next__)

        assert len(lines_1) == len(lines_2)

        result = []
        while True:
            try:
                for it in iters:
                    for _ in range(4):
                        result.append(it())
            except StopIteration:
                break

        files.append("\n".join(result))

    return files


class TestError(Exception):
    pass


class TestCase(object):
    def __init__(self, root, path):
        self.root = root
        self.path = path
        self.name = " :: ".join(path)
        self._files = self._collect_files(root)
        self._info = self._read_info(os.path.join(root, _INFO_FILE))
        self.skip = bool(self._info.get("skip"))

    def __repr__(self):
        return "TestCase(%r)" % (
            {
                "root": self.root,
                "name": self.name,
                "info": self._info,
                "files": self._files,
            }
        )

    def build(self, root, delete_folder):
        root = os.path.join(root, *self.path)

        interleaved_tests = [False]
        if self._is_properly_paired():
            interleaved_tests.append(True)

        parameters = itertools.product(
            (UNCOMPRESSED, GZIP),
            (UNCOMPRESSED, GZIP),
            interleaved_tests,
        )

        for in_compression, out_compression, interleaved in parameters:
            label = "%s>%s%s" % (
                in_compression,
                out_compression,
                ",intl" if interleaved else "",
            )

            args = ()
            kwargs = {
                "root": root,
                "in_compression": in_compression,
                "out_compression": out_compression,
                "interleaved": interleaved,
                "delete_folder": delete_folder,
            }

            yield self, label, args, kwargs
            if not self._info["exhaustive"]:
                break

    def __call__(
        self,
        root,
        in_compression=UNCOMPRESSED,
        out_compression=UNCOMPRESSED,
        interleaved=False,
        delete_folder=False,
    ):
        assert in_compression in (UNCOMPRESSED, GZIP)
        assert out_compression in (UNCOMPRESSED, GZIP)

        root = os.path.join(
            root,
            "%s_%s%s"
            % (
                in_compression,
                out_compression,
                "_intl" if interleaved else "",
            ),
        )

        os.makedirs(root)

        input_1, input_2 = self._setup_input(root, in_compression, interleaved)
        command = self._build_command(
            root, input_1, input_2, out_compression, interleaved
        )

        try:
            self._do_call(root, command)

            self._check_file_creation(root, input_1, input_2, out_compression)
            self._check_file_contents(root, out_compression)
        except TestError as error:
            raise TestError(
                "Command = %s\nDirectory = %s\n%s"
                % (" ".join(quote(value) for value in command), quote(root), error)
            )

        if delete_folder:
            shutil.rmtree(root)

    def _setup_input(self, root, compression, interleaved):
        input_files = {}
        for key in ("input_1", "input_2"):
            input_files[key] = [open(filename).read() for filename in self._files[key]]

        if interleaved:
            input_files = {
                "input_1": interleave(input_files["input_1"], input_files["input_2"]),
                "input_2": [],
            }

        final_files = {}
        for key, values in input_files.items():
            filenames = []
            for idx, value in enumerate(values):
                value = value.encode("utf-8")
                filename = "%s%s.fastq" % (key, chr(ord("a") + idx))
                if compression != UNCOMPRESSED:
                    filename += "." + compression
                    value = compress(value, compression)

                with open(os.path.join(root, filename), "wb") as handle:
                    handle.write(value)

                filenames.append(filename)

            final_files[key] = filenames

        if "barcodes" in self._files:
            with open(os.path.join(root, "barcodes.txt"), "w") as handle:
                handle.writelines(self._files["barcodes"])

        if "adapters" in self._files:
            with open(os.path.join(root, "adapters.txt"), "w") as handle:
                handle.writelines(self._files["adapters"])

        return final_files["input_1"], final_files["input_2"]

    def _do_call(self, root, command):
        proc = subprocess.Popen(
            command,
            stdin=subprocess.DEVNULL,
            stdout=subprocess.PIPE,
            stderr=subprocess.PIPE,
            close_fds=True,
            preexec_fn=os.setsid,
            cwd=root,
        )

        try:
            stdout, stderr = proc.communicate()
        except:
            proc.terminate()
            raise

        stdout = stdout.decode("utf-8")
        stderr = stderr.decode("utf-8")

        if stdout and not self._info["stdout"]:
            raise TestError("Unexpected output to STDOUT: %r" % (stdout,))

        for name, output in (("stdout", stdout), ("stderr", stderr)):
            for value in self._info[name]:
                if re.search(value, output) is None:
                    raise TestError(
                        "Expected value not found in output:\n"
                        "  Searching for:\n%s\n  %s:\n%s"
                        % (pretty_output(value, 4), name, pretty_output(output, 4))
                    )

        if proc.returncode != self._info["return_code"]:
            raise TestError(
                "Expected return-code %i, but AdapterRemoval returned %i:\n%s"
                % (
                    self._info["return_code"],
                    proc.returncode,
                    pretty_output(stderr, 2),
                )
            )

    def _check_file_creation(self, root, input_1, input_2, compression):
        expected_files = set(self._files["output"])
        for key in ("barcodes", "adapters"):
            if key in self._files:
                expected_files.add(key + ".txt")

        if compression != UNCOMPRESSED:
            expected_files_ = set()
            for value in expected_files:
                if not (value.endswith("settings") or value.endswith(".txt")):
                    expected_files_.add(value + "." + compression)
                else:
                    expected_files_.add(value)
            expected_files = expected_files_

        observed_files = (
            frozenset(os.listdir(root)) - frozenset(input_1) - frozenset(input_2)
        )

        # FIXME: To be cleaned up once JSON format has stabalized
        expected_files = set(
            fname for fname in expected_files if not fname.endswith(".settings")
        )
        observed_files = set(
            fname
            for fname in observed_files
            if not (fname.endswith(".json") or fname.endswith(".html"))
        )

        if expected_files != observed_files:
            message = ["Output files do not match expectations"]

            unexpected_files = sorted(observed_files - expected_files)
            if unexpected_files:
                message.append("  Unexpected files: {}".format(unexpected_files))

            missing_files = sorted(expected_files - observed_files)
            if missing_files:
                message.append("  Missing files:    {}".format(missing_files))

            raise TestError("\n".join(message))

    def _check_file_contents(self, root, compression):
        for filename, exp_data in sorted(self._files["output"].items()):
            # FIXME: To be removed once old setting files have been cleaned up
            if filename.endswith(".settings"):
                continue

            obs_filename = os.path.join(root, filename)
            if compression != UNCOMPRESSED:
                if not filename.endswith(".json"):
                    obs_filename += "." + compression

            obs_data = decompress(obs_filename)
            if filename.endswith(".json"):
                exp_data = self._mangle_settings(exp_data)
                obs_data = self._mangle_settings(obs_data)

            self._diff_file_pair_contents(
                os.path.join(self.root, filename),
                os.path.join(root, filename),
                exp_data,
                obs_data,
            )

    def _diff_file_pair_contents(self, exp_filename, obs_filename, exp_data, obs_data):
        if exp_data != obs_data:
            lines = "".join(
                difflib.unified_diff(exp_data, obs_data, "expected", "observed")
            )

            raise TestError(
                "Output file(s) differ:\n"
                "  Test:      %s\n  Expected: %r\n  Observed: %r\n  Diff:\n%s"
                % (self.root, exp_filename, obs_filename, pretty_output(lines, 4))
            )

    def _build_command(self, root, input_1, input_2, compression, interleaved):
        command = [os.path.abspath(_EXEC)]
        if interleaved:
            command.append("--interleaved-input")

        if "barcodes" in self._files:
            command.extend(("--barcode-list", "barcodes.txt"))

        if input_1 or input_2:
            if compression == GZIP:
                command.append("--gzip")

        if input_1:
            command.append("--file1")
            command.extend(input_1)
        if input_2:
            command.append("--file2")
            command.extend(input_2)

        command.extend(self._info["arguments"])

        return [field % {"ROOT": root} for field in command]

    def _is_properly_paired(self):
        def _count_lines(filenames):
            line_count = 0
            for filename in filenames:
                with open(filename) as handle:
                    line_count += sum(1 for line in handle)

            return line_count

        input_1_lines = _count_lines(self._files["input_1"])
        input_2_lines = _count_lines(self._files["input_2"])

        return input_1_lines and input_1_lines == input_2_lines

    @classmethod
    def _mangle_settings(cls, handle):
        result = json.loads("".join(handle))
        result.pop("meta")

        return result

    @classmethod
    def _collect_files(cls, root):
        result = {
            "input_1": [],
            "input_2": [],
            "output": {},
        }

        def read_lines(root, filename):
            return open(os.path.join(root, filename)).readlines()

        abs_root = os.path.abspath(root)
        for filename in sorted(os.listdir(root)):
            if filename.startswith("input_1"):
                result["input_1"].append(os.path.join(abs_root, filename))
            elif filename.startswith("input_2"):
                result["input_2"].append(os.path.join(abs_root, filename))
            elif filename == "barcodes.txt":
                result["barcodes"] = read_lines(root, filename)
            elif filename == "adapters.txt":
                result["adapters"] = read_lines(root, filename)
            elif filename not in ("info.json", "README"):
                result["output"][filename] = read_lines(root, filename)

        return result

    @classmethod
    def _read_info(cls, filename):
        with open(filename) as handle:
            text = handle.read()
            raw_info = json.loads(text)

        if not isinstance(raw_info, dict):
            raise TestError("'info.json' does not contain dictionary.")
        elif set(raw_info) - set(_INFO_FIELDS):
            raise TestError(
                "'info.json' does contains unexpected fields; "
                "expected keys %r, but found keys unknown keys %r."
                % (sorted(_INFO_FIELDS), sorted(set(raw_info) - set(_INFO_FIELDS)))
            )

        info = {
            "arguments": [],
            "return_code": 0,
            "stderr": [],
            "stdout": [],
            "exhaustive": True,
            "skip": False,
        }

        info.update(raw_info)

        for key, expected_type in _INFO_FIELDS.items():
            if not isinstance(info[key], expected_type):
                raise TestError(
                    "Type of %r in 'info.json' is %s, not a %s."
                    % (key, type(info[key]), expected_type)
                )
            elif isinstance(info[key], list):
                for value in info[key]:
                    if not isinstance(value, str):
                        raise TestError(
                            "Type of value in %r in 'info.json' "
                            "is %s, not a string." % (key, type(value))
                        )

        return info

    @classmethod
    def collect(cls, root, path=()):
        tests = []

        for filename in sorted(os.listdir(root)):
            filepath = os.path.join(root, filename)

            if os.path.isdir(filepath):
                tests.extend(cls.collect(filepath, path + (filename,)))
            elif filename == "info.json":
                try:
                    test = TestCase(root, path)
                except Exception as error:
                    print_err(
                        "ERROR: %s reading test %r: %s"
                        % (error.__class__.__name__, " :: ".join(path), error)
                    )
                    continue

                tests.append(test)

        return tests


def try_rmdir(dirpath):
    try:
        os.rmdir(dirpath)

        return True
    except OSError as error:
        if error.errno != errno.ENOTEMPTY:
            raise

    return False


def cleanup_dirs(root):
    has_children = False
    for child in os.scandir(root):
        if child.is_dir(follow_symlinks=False):
            if not cleanup_dirs(child.path):
                has_children = True
        else:
            has_children = True

    if not has_children:
        os.rmdir(root)

    return not has_children


def run_test(args):
    obj, label, args, kwargs = args

    try:
        if not obj.skip:
            obj(*args, **kwargs)
    except Exception as error:
        return obj, label, error

    return obj, label, None


def parse_args(argv):
    parser = argparse.ArgumentParser()
    parser.add_argument("work_dir", help="Directory in which to run test-cases.")
    parser.add_argument("source_dir", help="Directory containing test-cases.")
    parser.add_argument(
        "--max-failures",
        type=int,
        default=5,
        help="Maximum number of failures to report. Set to zero or less for no limit",
    )
    parser.add_argument(
        "--keep-all",
        help="Keep both completed and failed test folders, "
        "not just the folders of failed tests.",
    )
    parser.add_argument(
        "--threads",
        type=int,
        default=min(4, multiprocessing.cpu_count()),
        help="Size of thread-pool for concurrent execution of tests",
    )

    return parser.parse_args(argv)


def main(argv):
    args = parse_args(argv)
    if not os.path.exists(_EXEC):
        print_err("ERROR: Executable does not exist: %r" % (_EXEC,))
        return 1

    if args.max_failures <= 0:
        args.max_failures = float("inf")

    print("Reading test-cases from %r" % (args.source_dir,))
    tests = TestCase.collect(args.source_dir)
    tests.sort(key=lambda it: it.path)

    if not os.path.exists(args.work_dir):
        os.makedirs(args.work_dir)

    args.work_dir = tempfile.mkdtemp(dir=args.work_dir)
    print("Writing test-cases results to %r" % (args.work_dir,))

    tests_calls = []
    print("Building tests functions")
    for test in tests:
        tests_calls.extend(test.build(args.work_dir, not args.keep_all))

    n_failures = 0
    n_successes = 0
    n_skipped = 0
    print("\nRunning tests:")

    with multiprocessing.Pool(args.threads) as pool:
        results = pool.imap(run_test, tests_calls)
        grouped_results = groupby(results, lambda it: it[0].name)

        for idx, (name, test_results) in enumerate(grouped_results, start=1):
            print("  %i of %i: %s " % (idx, len(tests), name), end="")

            last_error = None
            last_variant = None
            test_skipped = False
            for test, variant, error in test_results:
                if test.skip:
                    print_ok(".", end="")
                    test_skipped = True
                elif error is None:
                    print_ok(".", end="")
                    sys.stdout.flush()
                else:
                    print_err("X", end="")
                    sys.stdout.flush()
                    if last_error is None:
                        last_error = error
                        last_variant = variant

            if test_skipped:
                print_warn(" [SKIPPED]")
                n_skipped += 1
            elif last_error is None:
                n_successes += 1
                print_ok(" [OK]")
            else:
                n_failures += 1
                message = "\n    ".join(str(last_error).split("\n"))
                print_err(
                    "\n  %s for %s:\n    %s"
                    % (last_error.__class__.__name__, last_variant, message)
                )

                if n_failures >= args.max_failures:
                    pool.terminate()
                    break

    cleanup_dirs(args.work_dir)

    if n_failures >= args.max_failures:
        print_err("\nAborted after %i of %i tests failed." % (n_failures, n_successes))
    elif n_failures:
        print_err("\n%i of %i tests failed." % (n_failures, len(tests)))
    else:
        print_ok("\nAll %i tests succeeded." % (len(tests),))

    if n_skipped:
        print_warn("Skipped {} tests!".format(n_skipped))

    return n_failures


if __name__ == "__main__":
    sys.exit(main(sys.argv[1:]))
